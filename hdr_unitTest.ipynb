{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hand-written digit recognition (hdr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "import math\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "This class does some initial training of a neural network for predicting drawn\n",
    "digits based on a data set in data_matrix and data_labels. It can then be used to\n",
    "train the network further by calling train() with any array of data or to predict\n",
    "what a drawn digit is by calling predict().\n",
    "\n",
    "The weights that define the neural network can be saved to a file, NN_FILE_PATH,\n",
    "to be reloaded upon initilization.\n",
    "\"\"\"\n",
    "\n",
    "class HdrNeuralNetwork:\n",
    "    WIDTH_IN_PIXELS = 20\n",
    "    LEARNING_RATE = 0.1\n",
    "    # for online learning\n",
    "    NN_FILE_PATH = 'nn.json'\n",
    "\n",
    "    def __init__(self, num_hidden_nodes, data_matrix, data_labels, use_file=True):\n",
    "        self.num_hidden_nodes = num_hidden_nodes\n",
    "        self._use_file = use_file \n",
    "        # self.theta1\n",
    "        # self.theta2\n",
    "        \n",
    "        self.LAMBDA = 0\n",
    "        # for regularization of the cost function        \n",
    "        self.sigmoid = np.vectorize(self._sigmoid_scalar)\n",
    "        self.sigmoid_prime = np.vectorize(self._sigmoid_prime_scalar)\n",
    "        self.data_matrix = data_matrix # 2-D list\n",
    "        self.data_labels = data_labels # 1-D list\n",
    "        self.sample_num = len(self.data_labels)\n",
    "\n",
    "        if (not os.path.isfile(HdrNeuralNetwork.NN_FILE_PATH) or not use_file):\n",
    "            # it could also be self.NN_FILE_PATH\n",
    "            # Step 1: Initialize weights to small numbers\n",
    "            self.theta1 = self._rand_initialize_weights(self.num_hidden_nodes, 400+1)\n",
    "            # num_hidden_nodes*401 matrix, the one is the bias\n",
    "            self.theta2 = self._rand_initialize_weights(10, self.num_hidden_nodes+1)\n",
    "            # 10*(num_hidden_nodes+1) matrix, the one is the bias\n",
    "\n",
    "            # Train using sample data\n",
    "            TrainData = namedtuple('TrainData', ['fig', 'label'])\n",
    "            the_temp = tuple(np.row_stack((self.theta1.flatten(1).T, self.theta2.flatten(1).T)).T.tolist()[0])\n",
    "            theta0 = np.asarray(the_temp) \n",
    "            args = tuple([TrainData(self.data_matrix[i], int(self.data_labels[i])) for i in range(self.sample_num)])\n",
    "            # print 'Values of the cost function:'\n",
    "            print 'Start to optimize the cost function...'\n",
    "            \n",
    "            res = optimize.fmin_cg(self._nnCostFunction, theta0, fprime=self._nnGrad, args=args, gtol=1e-3, maxiter=200)\n",
    "            # gtol=1e-5, 1e-3; maxiter=None, 2, 200*6175 (default?), 1*6175, 200, 50, 100\n",
    "            res = np.mat(res)\n",
    "            self.theta1 = np.reshape(res[0,0:self.num_hidden_nodes*401], (400+1, self.num_hidden_nodes)).T\n",
    "            self.theta2 = np.reshape(res[0,self.num_hidden_nodes*401:], (self.num_hidden_nodes+1, 10)).T\n",
    "            # self.train([TrainData(self.data_matrix[i], int(self.data_labels[i])) for i in range(self.sample_num)])\n",
    "\n",
    "            self.save()\n",
    "        else:\n",
    "            self._load()\n",
    "\n",
    "    def _rand_initialize_weights(self, size_in, size_out):\n",
    "        return np.mat(np.random.rand(size_out, size_in)*0.24-0.12)\n",
    "        # return np.mat(np.random.rand(size_out, size_in)*0.12-0.06)\n",
    "\n",
    "    # The sigmoid activation function. Operates on scalars.\n",
    "    def _sigmoid_scalar(self, z):\n",
    "        return 1 / (1 + math.e ** -z)\n",
    "\n",
    "    def _sigmoid_prime_scalar(self, z):\n",
    "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
    "\n",
    "    def draw(self, sample):\n",
    "        # sample is a list? with 20*WIDTH_IN_PIXELS pixels for the hand-written digit\n",
    "        pixelArray = [sample[j:j+self.WIDTH_IN_PIXELS] for j in xrange(0, len(sample), self.WIDTH_IN_PIXELS)]\n",
    "        # xrange(start, stop[, step]), list comprehension, a list of lists, 2D list\n",
    "        plt.imshow(zip(*pixelArray), cmap = cm.Greys_r, interpolation=\"nearest\")\n",
    "        # imshow is used to plot the image\n",
    "        # zip returns a list of tuples, an array_like list, the grayscale (not a colormap)\n",
    "        # One common place that interpolation happens is when you resize an image\n",
    "        plt.show()\n",
    "        # show is used to show the plot\n",
    "\n",
    "    def _nnCostFunction(self, the_thetas, *args):\n",
    "        \n",
    "        the_thetas = np.mat(the_thetas)\n",
    "        theta1 = np.reshape(the_thetas[0,0:self.num_hidden_nodes*401], (400+1, self.num_hidden_nodes)).T\n",
    "        theta2 = np.reshape(the_thetas[0,self.num_hidden_nodes*401:], (self.num_hidden_nodes+1, 10)).T\n",
    "        training_data_array = args\n",
    "        \n",
    "        J=0        \n",
    "        for data in training_data_array:\n",
    "            a1 = np.mat(data.fig).T\n",
    "            # 400*1 matrix\n",
    "            z2 = np.dot(theta1, np.row_stack((1, a1)))\n",
    "            # num_hidden_nodes*1 matrix\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            z3 = np.dot(theta2, np.row_stack((1, a2)))\n",
    "            # 10*1 matrix\n",
    "            a3 = self.sigmoid(z3)\n",
    "\n",
    "            y = [0] * 10 # y is a python list for easy initialization and is later turned into an np matrix (3 lines down).\n",
    "            y[data.label] = 1\n",
    "            # 1*10 list          \n",
    "            \n",
    "            for j in range(10):\n",
    "                J = J + np.mat(y).T[j,0]*math.log(a3[j,0])+(1-np.mat(y).T[j,0])*math.log(1-a3[j,0])\n",
    "                # numerically a3[j,0] could be smaller than 0 or larger than 1 a bit\n",
    "\n",
    "        J = -J/self.sample_num + self.LAMBDA/(2*self.sample_num)*(np.multiply(theta1[:,1:], theta1[:,1:]).sum()+np.multiply(theta2[:,1:], theta2[:,1:]).sum())\n",
    "        # print J \n",
    "        \n",
    "        return J\n",
    "        \n",
    "    def _nnGrad(self, the_thetas, *args):\n",
    "        \n",
    "        the_thetas = np.mat(the_thetas)\n",
    "        theta1 = np.reshape(the_thetas[0,0:self.num_hidden_nodes*401], (400+1, self.num_hidden_nodes)).T\n",
    "        theta2 = np.reshape(the_thetas[0,self.num_hidden_nodes*401:], (self.num_hidden_nodes+1, 10)).T\n",
    "        training_data_array = args\n",
    "        \n",
    "        Delta1 = np.mat(np.zeros(theta1.shape))\n",
    "        # num_hidden_nodes*401 matrix\n",
    "        Delta2 = np.mat(np.zeros(theta2.shape))\n",
    "        # 10*(num_hidden_nodes+1) matrix\n",
    "        theta1_grad = np.mat(np.zeros(theta1.shape))\n",
    "        theta2_grad = np.mat(np.zeros(theta2.shape))\n",
    "        \n",
    "        for data in training_data_array:\n",
    "            # Step 2: Forward propagation\n",
    "            a1 = np.mat(data.fig).T\n",
    "            # 400*1 matrix\n",
    "            z2 = np.dot(theta1, np.row_stack((1, a1)))\n",
    "            # num_hidden_nodes*1 matrix\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            z3 = np.dot(theta2, np.row_stack((1, a2)))\n",
    "            # 10*1 matrix\n",
    "            a3 = self.sigmoid(z3)\n",
    "            \n",
    "            # Step 3: Back propagation\n",
    "            y = [0] * 10 # y is a python list for easy initialization and is later turned into an np matrix (2 lines down).\n",
    "            y[data.label] = 1\n",
    "            # 1*10 list\n",
    "                      \n",
    "            delta3 = a3 - np.mat(y).T\n",
    "            # 10*1 matrix\n",
    "            z2plus = np.row_stack((0, z2))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = np.multiply(np.dot(theta2.T, delta3), self.sigmoid_prime(z2plus))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = delta2[1:,0]\n",
    "            # num_hidden_nodes*1 matrix\n",
    "                      \n",
    "            # Step 4: Sum delta*a.T and calculate the derivatives\n",
    "            Delta1 = Delta1 + np.dot(delta2, np.row_stack((1, a1)).T)\n",
    "            Delta2 = Delta2 + np.dot(delta3, np.row_stack((1, a2)).T)\n",
    "        \n",
    "        theta1_grad[:,0] = Delta1[:,0]/self.sample_num\n",
    "        theta2_grad[:,0] = Delta2[:,0]/self.sample_num\n",
    "        theta1_grad[:,1:] = Delta1[:,1:]/self.sample_num + self.LAMBDA/self.sample_num*theta1[:,1:]\n",
    "        theta2_grad[:,1:] = Delta2[:,1:]/self.sample_num + self.LAMBDA/self.sample_num*theta2[:,1:] \n",
    "        \n",
    "        ret = tuple(np.row_stack((theta1_grad.flatten(1).T, theta2_grad.flatten(1).T)).T.tolist()[0])\n",
    "        return np.asarray(ret)\n",
    "\n",
    "    def train(self, training_data_array):        \n",
    "        for data in training_data_array:\n",
    "            # Step 2: Forward propagation\n",
    "            a1 = np.mat(data.fig).T\n",
    "            # 400*1 matrix\n",
    "            z2 = np.dot(theta1, np.row_stack((1, a1)))\n",
    "            # num_hidden_nodes*1 matrix\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            z3 = np.dot(theta2, np.row_stack((1, a2)))\n",
    "            # 10*1 matrix\n",
    "            a3 = self.sigmoid(z3)\n",
    "\n",
    "            # Step 3: Back propagation\n",
    "            y = [0] * 10 # y is a python list for easy initialization and is later turned into an np matrix (2 lines down).\n",
    "            y[data.label] = 1\n",
    "            # 1*10 list\n",
    "                      \n",
    "            delta3 = a3 - np.mat(y).T\n",
    "            # 10*1 matrix\n",
    "            z2plus = np.row_stack((0, z2))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = np.multiply(np.dot(theta2.T, delta3), self.sigmoid_prime(z2plus))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = delta2[1:,0]\n",
    "            # num_hidden_nodes*1 matrix\n",
    "\n",
    "            # Step 4: Update weights\n",
    "            self.theta1 -= self.LEARNING_RATE * np.dot(delta2, np.row_stack((1, a1)).T)\n",
    "            self.theta2 -= self.LEARNING_RATE * np.dot(delta3, np.row_stack((1, a2)).T)\n",
    "\n",
    "    def predict(self, test):\n",
    "        a1 = np.mat(test).T\n",
    "        # 400*1 matrix\n",
    "        z2 = np.dot(self.theta1, np.row_stack((1, a1)))\n",
    "        # num_hidden_nodes*1 matrix\n",
    "        a2 = self.sigmoid(z2)\n",
    "\n",
    "        z3 = np.dot(theta2, np.row_stack((1, a2)))\n",
    "        # 10*1 matrix\n",
    "        a3 = self.sigmoid(z3)        \n",
    "\n",
    "        results = a3.T.tolist()[0]\n",
    "        return results.index(max(results))\n",
    "\n",
    "    def save(self):\n",
    "        if not self._use_file:\n",
    "            return\n",
    "\n",
    "        json_neural_network = {\n",
    "            \"theta1\":self.theta1.flatten(1).tolist()[0],\n",
    "            \"theta2\":self.theta2.flatten(1).tolist()[0]\n",
    "        };\n",
    "        with open(HdrNeuralNetwork.NN_FILE_PATH,'w') as nnFile:\n",
    "            json.dump(json_neural_network, nnFile)\n",
    "            \n",
    "        print 'nn.json is now saved'\n",
    "\n",
    "    def _load(self):\n",
    "        if not self._use_file:\n",
    "            return\n",
    "\n",
    "        with open(HdrNeuralNetwork.NN_FILE_PATH) as nnFile:\n",
    "            nn = json.load(nnFile)\n",
    "        self.theta1 = np.reshape(np.mat(nn['theta1']), (400+1, self.num_hidden_nodes)).T \n",
    "        self.theta2 = np.reshape(np.mat(nn['theta2']), (self.num_hidden_nodes+1, 10)).T \n",
    "        \n",
    "        print 'reloading previous nn.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reloading previous nn.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  2.33445204e-04,  -2.57668497e-05,   2.49921903e-04, ...,\n",
       "        -7.15465425e-05,  -5.27062979e-04,   7.69930553e-05])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "HIDDEN_NODE_COUNT = 15\n",
    "data_matrix = np.loadtxt(open('data.csv', 'rb'), delimiter = ',')\n",
    "data_labels = np.loadtxt(open('dataLabels.csv', 'rb'))\n",
    "\n",
    "data_matrix = data_matrix.tolist()\n",
    "# print data_matrix[0:2]\n",
    "data_labels = data_labels.tolist()\n",
    "# print data_labels[0:2]\n",
    "\n",
    "nn = HdrNeuralNetwork(HIDDEN_NODE_COUNT, data_matrix, data_labels)\n",
    "nn._rand_initialize_weights(400, 15)\n",
    "nn._sigmoid_scalar(-100)\n",
    "nn._sigmoid_scalar(100)\n",
    "\n",
    "the_temp = tuple(np.row_stack((nn.theta1.flatten(1).T, nn.theta2.flatten(1).T)).T.tolist()[0])\n",
    "theta0 = np.asarray(the_temp)\n",
    "TrainData = namedtuple('TrainData', ['fig', 'label'])\n",
    "args_li = [TrainData(nn.data_matrix[i], int(nn.data_labels[i])) for i in range(nn.sample_num)]\n",
    "nn._nnCostFunction(theta0, *args_li)\n",
    "nn._nnGrad(theta0, *args_li) \n",
    "# numpy.allclose(arr1, arr2), numpy.testing.assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "# import os\n",
    "# datadir=os.path.join(os.path.expanduser('~'),'Documents','workspace','data')\n",
    "    \n",
    "class TestHdrNeuralNetwork(unittest.TestCase):\n",
    "    \n",
    "    def test__sigmoid_scalar(self):\n",
    "        self.assertEqual(nn._sigmoid_scalar(0), 0.5)\n",
    "        self.assertAlmostEqual(nn._sigmoid_scalar(-100), 0)\n",
    "        self.assertAlmostEqual(nn._sigmoid_scalar(100), 1)\n",
    "        \n",
    "    def test__sigmoid_prime_scalar(self):\n",
    "        self.assertEqual(nn._sigmoid_prime_scalar(0), 0.25)\n",
    "        self.assertAlmostEqual(nn._sigmoid_prime_scalar(-100), 0)\n",
    "        self.assertAlmostEqual(nn._sigmoid_prime_scalar(100), 0)\n",
    "    \n",
    "    def test__nnCostFunction(self):\n",
    "        self.assertAlmostEqual(nn._nnCostFunction(theta0, *args_li), 0.20323933)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 2.617s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestHdrNeuralNetwork)\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
